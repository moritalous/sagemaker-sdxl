{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4f3708-862d-4537-99ab-494ee25e8433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "local_dir = './model'\n",
    "snapshot_download(\n",
    "    repo_id=\"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "    allow_patterns=\"sd_xl_base_1.0.safetensors\",\n",
    "    local_dir=local_dir,\n",
    "    local_dir_use_symlinks=False)\n",
    "snapshot_download(\n",
    "    repo_id=\"stabilityai/stable-diffusion-xl-refiner-1.0\",\n",
    "    allow_patterns=\"sd_xl_refiner_1.0.safetensors\",\n",
    "    local_dir=local_dir,\n",
    "    local_dir_use_symlinks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4726a8c5-5269-4687-8086-def74e9dd218",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "aws s3 cp s3://sagemaker-sdxl/output/1725806787/lora-trained-xl/pytorch_lora_weights.safetensors model/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d734a9c-63d0-42ed-bd26-7d465c5ad5c6",
   "metadata": {},
   "source": [
    "### 3. Package and upload model archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf93aa3-0815-4fbe-b007-62594165f0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket = None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23635fc1-d590-47c4-8a7a-b6154aa5fd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerun this cell only if you need to re-upload the weights, otherwise you can reuse the existing model_package_name and upload only your new code\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "# You may want to make this a fixed name of your choosing instead\n",
    "model_package_name = name_from_base(f\"sdxl-v1\")\n",
    "model_uri = f's3://{sagemaker_session_bucket}/{model_package_name}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e5fd90-4815-41e9-9907-9503cddbedab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Uploading base model to {model_uri}, this will take a while...')\n",
    "!aws s3 cp model/sd_xl_base_1.0.safetensors {model_uri}\n",
    "print(f'Uploading refiner model to {model_uri}, this will take a while...')\n",
    "!aws s3 cp model/sd_xl_refiner_1.0.safetensors {model_uri}\n",
    "print(f'Uploading LoRA weights to {model_uri}, this will take a while...')\n",
    "!aws s3 cp model/pytorch_lora_weights.safetensors {model_uri}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddc12ba-de98-468b-894f-567d0f9aac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerun this cell when you have changed the code or are uploading a fresh copy of the weights\n",
    "print(f'Uploading code to {model_uri}code')\n",
    "!aws s3 cp model/code/inference.py {model_uri}code/inference.py\n",
    "!aws s3 cp model/code/requirements.txt {model_uri}code/requirements.txt\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048a58c7-9637-4d7d-9a1a-5e83e14a4a08",
   "metadata": {},
   "source": [
    "### 4. Create and deploy a model and perform real-time inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31ed6649-1fc8-4f06-8eb7-ae86ca9b780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please only use regions with g5 instance support, mentioned at the top of this page\n",
    "inference_image_uri_region = \"us-east-1\"\n",
    "\n",
    "inference_image_uri_region_acct = \"763104351884\"\n",
    "\n",
    "inference_image_uri = f\"{inference_image_uri_region_acct}.dkr.ecr.{inference_image_uri_region}.amazonaws.com/stabilityai-pytorch-inference:2.0.1-sgm0.1.0-gpu-py310-cu118-ubuntu20.04-sagemaker\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952aa000-44bb-4977-be02-dda46cc56f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = name_from_base(f\"sdxl-v1\")\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "create_model_response = sagemaker_client.create_model(\n",
    "    ModelName=endpoint_name,\n",
    "    ExecutionRoleArn=role,\n",
    "    PrimaryContainer={\n",
    "        \"Image\": inference_image_uri,\n",
    "        \"ModelDataSource\": {\n",
    "            \"S3DataSource\": {               # S3 Data Source configuration:\n",
    "                \"S3Uri\": model_uri,         # path to your model and script\n",
    "                \"S3DataType\": \"S3Prefix\",   # causes SageMaker to download from a prefix\n",
    "                \"CompressionType\": \"None\"   # disables compression\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "create_endpoint_config_response = sagemaker_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_name,\n",
    "    ProductionVariants=[{\n",
    "        \"ModelName\": endpoint_name,\n",
    "        \"VariantName\": \"sdxl\",\n",
    "        \"InitialInstanceCount\": 1,\n",
    "        \"InstanceType\": \"ml.g5.2xlarge\",     # 4xlarge is required to load the model\n",
    "    }]\n",
    ")\n",
    "\n",
    "\n",
    "deploy_model_response = sagemaker_client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_name\n",
    ")\n",
    "\n",
    "print('Waiting for the endpoint to be in service, this can take 5-10 minutes...')\n",
    "waiter = sagemaker_client.get_waiter('endpoint_in_service')\n",
    "waiter.wait(EndpointName=endpoint_name)\n",
    "print(f'Endpoint {endpoint_name} is in service, but the model is still loading. This may take another 5-10 minutes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1cdff1-1488-45c4-810d-0608cc89fd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.deserializers import BytesDeserializer\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "\n",
    "# Create a predictor with proper serializers\n",
    "deployed_model = Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sess,\n",
    "    # serializer=JSONSerializer(),\n",
    "    # deserializer=BytesDeserializer(accept=\"image/png\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ba26d1-1c91-452a-aadf-65232f22cb7b",
   "metadata": {},
   "source": [
    "---\n",
    "# Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afa591c-1687-49db-a52a-33573f69c03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "import json\n",
    "\n",
    "from diffusers.utils import load_image\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def image_to_base64(image: Image.Image) -> str:\n",
    "    \"\"\"Convert a PIL Image to a base64 string\"\"\"\n",
    "    buffer = io.BytesIO()\n",
    "    image.save(buffer, format=\"PNG\")\n",
    "    return base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def base64_to_image(base64_image: str) -> Image.Image:\n",
    "    \"\"\"Convert a base64 string to a PIL Image\"\"\"\n",
    "    return Image.open(io.BytesIO(base64.decodebytes(bytes(base64_image, \"utf-8\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d971bd-e672-4a90-ab8e-d309a58e7ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# txt2img\n",
    "body = json.dumps(\n",
    "    {\n",
    "        \"text_prompts\": [{\"text\": \"a sks dog sitting on a bench\"}],\n",
    "    }\n",
    ")\n",
    "\n",
    "response = deployed_model.predict(body)\n",
    "\n",
    "response_body = json.loads(response)\n",
    "artifacts = response_body[\"artifacts\"]\n",
    "\n",
    "image = base64_to_image(artifacts)\n",
    "image.save(\"out1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f185d6-8d0b-434a-9b92-66dd4809ec7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img2img\n",
    "url = \"https://huggingface.co/datasets/patrickvonplaten/images/resolve/main/aa_xl/000000009.png\"\n",
    "\n",
    "init_image = load_image(url).convert(\"RGB\")\n",
    "\n",
    "body = json.dumps(\n",
    "    {\n",
    "        \"text_prompts\": [{\"text\": \"a sks dog sitting on a bench\"}],\n",
    "        \"init_image\": image_to_base64(init_image),\n",
    "        # \"image_strength\": 0.8\n",
    "    }\n",
    ")\n",
    "\n",
    "response = deployed_model.predict(body)\n",
    "\n",
    "response_body = json.loads(response)\n",
    "artifacts = response_body[\"artifacts\"]\n",
    "\n",
    "image = base64_to_image(artifacts)\n",
    "image.save(\"out2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b211399a-0681-45b9-9a1b-d944f7d429a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inpaint\n",
    "img_url = \"https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png\"\n",
    "mask_url = \"https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png\"\n",
    "\n",
    "init_image = load_image(img_url).convert(\"RGB\")\n",
    "mask_image = load_image(mask_url).convert(\"RGB\")\n",
    "\n",
    "body = json.dumps(\n",
    "    {\n",
    "        \"text_prompts\": [{\"text\": \"cat\"}],\n",
    "        \"init_image\": image_to_base64(init_image),\n",
    "        \"mask_image\": image_to_base64(mask_image),\n",
    "        # \"image_strength\": 0.8\n",
    "    }\n",
    ")\n",
    "\n",
    "response = deployed_model.predict(body)\n",
    "\n",
    "response_body = json.loads(response)\n",
    "artifacts = response_body[\"artifacts\"]\n",
    "\n",
    "image = base64_to_image(artifacts)\n",
    "image.save(\"out3.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
